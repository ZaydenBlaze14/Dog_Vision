{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "end-to-end-dog-vision.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZeHfjvj5xcp"
      },
      "source": [
        "# Using Transfer Learning and TensorFlow 2.0 to Classify Different Dog Breeds\n",
        "\n",
        "\n",
        "We'll be using data from the [Kaggle dog breed identification competition](https://www.kaggle.com/c/dog-breed-identification/overview). It consists of a collection of 10,000+ labelled images of 120 different dog breeds.\n",
        "\n",
        "\n",
        "We're going to go through the following TensorFlow/Deep Learning workflow:\n",
        "1. Get data ready (download from Kaggle, store, import).\n",
        "2. Prepare the data (preprocessing, the 3 sets, X & y).\n",
        "3. Choose and fit/train a model ([TensorFlow Hub](https://www.tensorflow.org/hub), `tf.keras.applications`, [TensorBoard](https://www.tensorflow.org/tensorboard), [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)).\n",
        "4. Evaluating a model (making predictions, comparing them with the ground truth labels).\n",
        "5. Improve the model through experimentation (start with 1000 images, make sure it works, increase the number of images).\n",
        "6. Save, sharing and reloading your model (once you're happy with the results).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ325_fg7QZg"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "\n",
        "# Check for GPU\n",
        "print(\"GPU\", \"available (YES)\" if tf.config.list_physical_devices(\"GPU\") else \"not available \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmIMyr1j5n3z"
      },
      "source": [
        "## Getting data ready\n",
        "\n",
        "I will be using the data from my drive. Data can also be procured from Kaggle api."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWlN4oD4FXrz"
      },
      "source": [
        "# Running this cell will provide us with a token to link of the drive to this notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcAz5BLnFu7J"
      },
      "source": [
        "Following the prompts from the cell above, if everything worked, you should see a \"drive\" folder available under the Files tab.\n",
        "\n",
        "This means we'll be able to access files in our Google Drive right in this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N2BLsAhFnlV"
      },
      "source": [
        "# Use the '-d' parameter as the destination for where the files should go\n",
        "#!unzip \"drive/My Drive/Data/dog-breed-identification.zip\" -d \"drive/My Drive/Data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jWoK2aBGmZI"
      },
      "source": [
        "Once the files have been unzipped to your Google Drive, we don't have to run the cell above anymore.\n",
        "\n",
        "### Accessing the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv1Ayf1qGrI6"
      },
      "source": [
        "# Checkout the labels of our data\n",
        "import pandas as pd\n",
        "labels_csv = pd.read_csv(\"drive/My Drive/Data/labels.csv\")\n",
        "print(labels_csv.describe())\n",
        "print(labels_csv.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04sOtsyUHduj"
      },
      "source": [
        "Looking at this, we can see there are 10222 different ID's (meaning 10222 different images) and 120 different breeds.\n",
        "\n",
        "Let's figure out how many images there are of each breed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfH_jx6lIZbF"
      },
      "source": [
        "# How many images are there of each breed?\n",
        "labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20, 10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wt_Vy3BKfjI"
      },
      "source": [
        "#Sample\n",
        "\n",
        "from IPython.display import display, Image\n",
        "# Image(\"drive/My Drive/Data/train/000bec180eb18c7604dcecc8fe0dba07.jpg\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbYs5TX6L8hK"
      },
      "source": [
        "### Getting images and their labels\n",
        "\n",
        "Since we've got the image ID's and their labels in a DataFrame (`labels_csv`), we'll use it to create:\n",
        "* A list a filepaths to training images\n",
        "* An array of all labels\n",
        "* An array of all unique labels\n",
        "\n",
        "We'll only create a list of filepaths to images rather than importing them all to begin with. This is because working with filepaths (strings) is much efficient than working with images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7fpANVoRnGr"
      },
      "source": [
        "# Create pathnames from image ID's\n",
        "filenames = [\"drive/My Drive/Data/train/\" + fname + \".jpg\" for fname in labels_csv[\"id\"]]\n",
        "\n",
        "# Check the first 10 filenames\n",
        "filenames[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQa1N8cLSAMk"
      },
      "source": [
        "Now we've got a list of all the filenames from the ID column of `labels_csv`, we can compare it to the number of files in our training data directory to see if they line up.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX1Ll_QbR9sF"
      },
      "source": [
        "# Check whether number of filenames matches number of actual image files\n",
        "import os\n",
        "if len(os.listdir(\"drive/My Drive/Data/train/\")) == len(filenames):\n",
        "  print(\"Filenames match actual amount of files\")\n",
        "else:\n",
        "  print(\"Filenames do not match actual amount of files, check the target directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbzZjkoKS9u0"
      },
      "source": [
        "# Check an image directly from a filepath\n",
        "Image(filenames[9000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv7aNWb5TR-N"
      },
      "source": [
        "### Labels\n",
        "\n",
        "We'll take them from `labels_csv` and turn them into a NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9pYpJBpTD7w"
      },
      "source": [
        "import numpy as np\n",
        "labels = labels_csv[\"breed\"].to_numpy() # convert labels column to NumPy array\n",
        "labels[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjXvS4nXTn10"
      },
      "source": [
        "Comparing again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P0InW71TmIQ"
      },
      "source": [
        "# See if number of labels matches the number of filenames\n",
        "if len(labels) == len(filenames):\n",
        "  print(\"Number of labels matches number of filenames\")\n",
        "else:\n",
        "  print(\"Number of labels does not match number of filenames, check data directories.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-KkzGSGT0q6"
      },
      "source": [
        "###Convert Labels to Numbers as the model cannot take strings as input\n",
        "\n",
        "Then we'll go through the list of `labels` and compare them to unique breeds and create a list of booleans indicating which one is the real label (`True`) and which ones aren't (`False`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K6Oul0uUq4f"
      },
      "source": [
        "# Find the unique label values\n",
        "unique_breeds = np.unique(labels)\n",
        "len(unique_breeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF5MILPDU0ut"
      },
      "source": [
        "The length of `unique_breeds` should be 120\n",
        "\n",
        "Now use `unique_breeds` to help turn our `labels` array into an array of booleans."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Iq3n1SzVVk_"
      },
      "source": [
        "# Turn every label into a boolean array\n",
        "boolean_labels = [label == np.array(unique_breeds) for label in labels]\n",
        "boolean_labels[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwsmgI0qUID4"
      },
      "source": [
        "### Creating our own validation set\n",
        "\n",
        "The dataset from Kaggle doesn't come with a validation set we will make one.\n",
        "\n",
        "We could use Scikit-Learn's [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylTZ5QsV8jyX"
      },
      "source": [
        "# Setup X & y variables\n",
        "X = filenames\n",
        "y = boolean_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUUiacU_8ey"
      },
      "source": [
        "# Set number of images to use for experimenting\n",
        "NUM_IMAGES = 1000 #@param {type:\"slider\", min:1000, max:10000, step:1000}\n",
        "NUM_IMAGES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ6nPdYdBHMs"
      },
      "source": [
        "Now let's split our data into training and validation sets. We'll use and 80/20 split (80% training data, 20% validation data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6RNwMv3BD7N"
      },
      "source": [
        "# Import train_test_split from Scikit-Learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split them into training and validation using NUM_IMAGES \n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n",
        "                                                  y[:NUM_IMAGES], \n",
        "                                                  test_size=0.2,\n",
        "                                                  random_state=42)\n",
        "\n",
        "len(X_train), len(y_train), len(X_val), len(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVw0TrUQCfDa"
      },
      "source": [
        "# Check out the training data (image file paths and labels)\n",
        "X_train[:5], y_train[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrvNClHWUMPP"
      },
      "source": [
        "### Preprocessing images \n",
        "\n",
        "\n",
        "\n",
        "To preprocess our images into Tensors we're going to write a function which does a few things:\n",
        "1. Takes an image filename as input.\n",
        "2. Uses TensorFlow to read the file and save it to a variable, `image`.\n",
        "3. Turn our `image` (a jpeg file) into Tensors.\n",
        "4. Resize the `image` to be of shape (224, 224).\n",
        "5. Return the modified `image`.\n",
        "\n",
        "\n",
        "\n",
        "Size of input model takes an image which is (224, 224, 3).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezyHapaOG48I"
      },
      "source": [
        "# Define image size\n",
        "IMG_SIZE = 224\n",
        "\n",
        "def process_image(image_path):\n",
        "  \"\"\"\n",
        "  Takes an image file path and turns it into a Tensor.\n",
        "  \"\"\"\n",
        "  # Read in image file\n",
        "  image = tf.io.read_file(image_path)\n",
        "  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  # Convert the colour channel values from 0-225 values to 0-1 values\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  # Resize the image to our desired size (224, 244)\n",
        "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzAWUUFlPJMe"
      },
      "source": [
        "### Creating data batches\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXSG48e9PCAX"
      },
      "source": [
        "# Create a simple function to return a tuple (image, label)\n",
        "def get_image_label(image_path, label):\n",
        "  \"\"\"\n",
        "  Takes an image file path name and the associated label,\n",
        "  processes the image and returns a tuple of (image, label).\n",
        "  \"\"\"\n",
        "  image = process_image(image_path)\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p_uqJgY-Tlh"
      },
      "source": [
        "Now we've got a simple function to turn our image file path names and their associated labels into tuples (we can turn these into Tensors next), we'll create a function to make data batches.\n",
        "\n",
        "Because we'll be dealing with 3 different sets of data (training, validation and test), we'll make sure the function can accomodate for each set.\n",
        "\n",
        "We'll set a default batch size of 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNACj1SO-RpY"
      },
      "source": [
        "# Define the batch size, 32 is a good default\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create a function to turn data into batches\n",
        "def create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
        "  \"\"\"\n",
        "  Creates batches of data out of image (x) and label (y) pairs.\n",
        "  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n",
        "  Also accepts test data as input (no labels).\n",
        "  \"\"\"\n",
        "  # If the data is a test dataset, we probably don't have labels\n",
        "  if test_data:\n",
        "    print(\"Creating test data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n",
        "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "  \n",
        "  # If the data if a valid dataset, we don't need to shuffle it\n",
        "  elif valid_data:\n",
        "    print(\"Creating validation data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
        "                                               tf.constant(y))) # labels\n",
        "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  else:\n",
        "    # If the data is a training dataset, we shuffle it\n",
        "    print(\"Creating training data batches...\")\n",
        "    # Turn filepaths and labels into Tensors\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
        "                                              tf.constant(y))) # labels\n",
        "    \n",
        "    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n",
        "    data = data.shuffle(buffer_size=len(x))\n",
        "\n",
        "    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n",
        "    data = data.map(get_image_label)\n",
        "\n",
        "    # Turn the data into batches\n",
        "    data_batch = data.batch(BATCH_SIZE)\n",
        "  return data_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K7GbSTZMFgL"
      },
      "source": [
        "# Create training and validation data batches\n",
        "train_data = create_data_batches(X_train, y_train)\n",
        "val_data = create_data_batches(X_val, y_val, valid_data=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya6gI9ImMeBq"
      },
      "source": [
        "# Check out the different attributes of our data batches\n",
        "train_data.element_spec, val_data.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU3UCy-oIM6M"
      },
      "source": [
        "\n",
        "\n",
        "### Visualizing data batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou_fRHK2JMca"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a function for viewing images in a data batch\n",
        "def show_25_images(images, labels):\n",
        "  \"\"\"\n",
        "  Displays 25 images from a data batch.\n",
        "  \"\"\"\n",
        "  # Setup the figure\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  # Loop through 25 (for displaying 25 images)\n",
        "  for i in range(25):\n",
        "    # Create subplots (5 rows, 5 columns)\n",
        "    ax = plt.subplot(5, 5, i+1)\n",
        "    # Display an image\n",
        "    plt.imshow(images[i])\n",
        "    # Add the image label as the title\n",
        "    plt.title(unique_breeds[labels[i].argmax()])\n",
        "    # Turn gird lines off\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3xB9OynNM4w"
      },
      "source": [
        "To make computation efficient, a batch is a tighly wound collection of Tensors.\n",
        "\n",
        "So to view data in a batch, we've got to unwind it.\n",
        "\n",
        "We can do so by calling the [`as_numpy_iterator()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#as_numpy_iterator) method on a data batch.\n",
        "\n",
        "This will turn our a data batch into something which can be iterated over.\n",
        "\n",
        "Passing an iterable to [`next()`](https://docs.python.org/3/library/functions.html#next) will return the next item in the iterator.\n",
        "\n",
        "In our case, next will return a batch of 32 images and label pairs.\n",
        "\n",
        "**Note:** Running the cell below and loading images may take a little while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpNpypPuL_IJ"
      },
      "source": [
        "# Visualize training images from the training data batch\n",
        "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
        "show_25_images(train_images, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlnzt9mkN4n5"
      },
      "source": [
        "# Visualize validation images from the validation data batch\n",
        "val_images, val_labels = next(val_data.as_numpy_iterator())\n",
        "show_25_images(val_images, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xJY5J5zPrVN"
      },
      "source": [
        "# Creating and training a model\n",
        "\n",
        " We'll use an existing model from [TensorFlow Hub](https://tfhub.dev/).\n",
        "\n",
        "\n",
        "\n",
        "#### How do we choose a model?\n",
        "\n",
        "[TensorFlow Hub page by our problem domain (image)](https://tfhub.dev/s?module-type=image-augmentation,image-classification,image-feature-vector,image-generator,image-object-detection,image-others,image-style-transfer,image-rnn-agent). \n",
        "\n",
        "\n",
        "### Building a model\n",
        "\n",
        "Before we build a model, there are a few things we need to define:\n",
        "* The input shape (images, in the form of Tensors) to our model.\n",
        "* The output shape (image labels, in the form of Tensors) of our model.\n",
        "* The URL of the model we want to use.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J90ZIz7ZUgej"
      },
      "source": [
        "# Setup input shape to the model\n",
        "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n",
        "\n",
        "# Setup output shape of the model\n",
        "OUTPUT_SHAPE = len(unique_breeds) # number of unique labels\n",
        "\n",
        "# Setup model URL from TensorFlow Hub\n",
        "MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cahrszePYZ1m"
      },
      "source": [
        "\n",
        "\n",
        " Using the [Keras API](https://www.tensorflow.org/guide/keras/overview).\n",
        "\n",
        "\n",
        "\n",
        "Function:\n",
        "* Takes the input shape, output shape and the model we've chosen's URL as parameters.\n",
        "* Defines the layers in a Keras model in a sequential fashion (do this first, then this, then that).\n",
        "* Compiles the model (says how it should be evaluated and improved).\n",
        "* Builds the model (tells it what kind of input shape it'll be getting).\n",
        "* Returns the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjYKUMTWSmbB"
      },
      "source": [
        "# Create a function which builds a Keras model\n",
        "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n",
        "  print(\"Building model with:\", MODEL_URL)\n",
        "\n",
        "  # Setup the model layers\n",
        "  model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n",
        "    tf.keras.layers.Dense(units=OUTPUT_SHAPE, \n",
        "                          activation=\"softmax\") # Layer 2 (output layer)\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)\n",
        "      optimizer=tf.keras.optimizers.Adam(), # A friend telling our model how to improve its guesses\n",
        "      metrics=[\"accuracy\"] # We'd like this to go up\n",
        "  )\n",
        "\n",
        "  # Build the model\n",
        "  model.build(INPUT_SHAPE) # Let the model know what kind of inputs it'll be getting\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3_vCn0ZSj5M"
      },
      "source": [
        "# Create a model and check its details\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uErC_Mu5Xt7i"
      },
      "source": [
        "The non-trainable parameters are the patterns learned by `mobilenet_v2_130_224` and the trainable parameters are the ones in the dense layer we added.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KlmCVeSQzI8"
      },
      "source": [
        "### Creating callbacks\n",
        "\n",
        "Callbacks are helper functions a model can use during training to do things such as save a models progress, check a models progress or stop training early if a model stops improving.\n",
        "\n",
        "The two callbacks we're going to add are a TensorBoard callback and an Early Stopping callback.\n",
        "\n",
        "#### TensorBoard Callback\n",
        "\n",
        "[TensorBoard](https://www.tensorflow.org/tensorboard/get_started) helps provide a visual way to monitor the progress of your model during and after training.\n",
        "\n",
        "It can be used [directly in a notebook](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks) to track the performance measures of a model such as loss and accuracy.\n",
        "\n",
        "To set up a TensorBoard callback and view TensorBoard in a notebook, we need to do three things:\n",
        "1. Load the TensorBoard notebook extension.\n",
        "2. Create a TensorBoard callback which is able to save logs to a directory and pass it to our model's `fit()` function.\n",
        "3. Visualize the our models training logs using the `%tensorboard` magic function (we'll do this later on)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmIBcrkRSixu"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT94y1375t76"
      },
      "source": [
        "import datetime\n",
        "\n",
        "# Create a function to build a TensorBoard callback\n",
        "def create_tensorboard_callback():\n",
        "  # Create a log directory for storing TensorBoard logs\n",
        "  logdir = os.path.join(\"drive/My Drive/Data/logs\",\n",
        "                        # Make it so the logs get tracked whenever we run an experiment\n",
        "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  return tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0XksOKh6ozR"
      },
      "source": [
        "#### Early Stopping Callback\n",
        "\n",
        "[Early stopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) helps prevent overfitting by stopping a model when a certain evaluation metric stops improving. If a model trains for too long, it can do so well at finding patterns in a certain dataset that it's not able to use those patterns on another dataset it hasn't seen before (doesn't generalize).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD6bvwx26pE4"
      },
      "source": [
        "# Create early stopping (once our model stops improving, stop training)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                  patience=3) # stops after 3 rounds of no improvements"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwVbjazpRVFG"
      },
      "source": [
        "### Training a model (on a subset of data)\n",
        "Our first model is only going to be trained on 800 images and then validated on 200 images.\n",
        "We do this to make sure everything is working.\n",
        "\n",
        "The final parameter we'll define before training is `NUM_EPOCHS` (also known as **number of epochs**).\n",
        "\n",
        "`NUM_EPOCHS` defines how many passes of the data we'd like our model to do. A pass is equivalent to our model trying to find patterns in each dog image and see which patterns relate to each label.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I810g3EjSiTx"
      },
      "source": [
        "# Check again if GPU is available (otherwise computing will take a looooonnnnggggg time)\n",
        "print(\"GPU\", \"available (YES)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFe7tira73It"
      },
      "source": [
        "# How many rounds should we get the model to look through the data?\n",
        "NUM_EPOCHS = 100 #@param {type:\"slider\", min:10, max:100, step:10}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bi-smYQBG5R"
      },
      "source": [
        "We've got a GPU running and `NUM_EPOCHS` setup. Let's create a simple function which trains a model. The function will:\n",
        "* Create a model using `create_model()`.\n",
        "* Setup a TensorBoard callback using `create_tensorboard_callback()` (we do this here so it creates a log directory of the current date and time).\n",
        "* Call the `fit()` function on our model passing it the training data, validatation data, number of epochs to train for and the callbacks we'd like to use.\n",
        "* Return the fitted model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVG2q8Ep-ewd"
      },
      "source": [
        "# Build a function to train and return a trained model\n",
        "def train_model():\n",
        "  \"\"\"\n",
        "  Trains a given model and returns the trained version.\n",
        "  \"\"\"\n",
        "  # Create a model\n",
        "  model = create_model()\n",
        "\n",
        "  # Create new TensorBoard session everytime we train a model\n",
        "  tensorboard = create_tensorboard_callback()\n",
        "\n",
        "  # Fit the model to the data passing it the callbacks we created\n",
        "  model.fit(x=train_data,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            validation_data=val_data,\n",
        "            validation_freq=1, # check validation metrics every epoch\n",
        "            callbacks=[tensorboard, early_stopping])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVhwO0I-_68V"
      },
      "source": [
        "**Note:** When training a model for the first time, the first epoch will take a while to load compared to the rest. This is because the model is getting ready and the data is being initialised. Using more data will generally take longer, which is why we've started with ~1000 images. After the first epoch, subsequent epochs should take a few seconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfhEe6Kd72_3"
      },
      "source": [
        "# Fit the model to the data\n",
        "model = train_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFFrMi6SCa0t"
      },
      "source": [
        "**Question:** It looks like our model might be overfitting (getting far better results on the training set than the validation set), what are some ways to prevent model overfitting? Hint: this may involve searching something like \"ways to prevent overfitting in a deep learning model?\".\n",
        "\n",
        "**Note:** Overfitting to begin with is a good thing. It means our model is learning something."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q20ekX-J9NzM"
      },
      "source": [
        "#### Checking the TensorBoard logs\n",
        "Now our model has been trained, we can make its performance visual by checking the TensorBoard logs.\n",
        "\n",
        "The TensorBoard magic function (`%tensorboard`) will access the logs directory we created earlier and viualize its contents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFEkauCk9Lt2"
      },
      "source": [
        "%tensorboard --logdir drive/My\\ Drive/Data/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_SNpayMBxz4"
      },
      "source": [
        "Thanks to  `early_stopping` callback, the model stopped training after 26 or so epochs. This is because the validation accuracy failed to improve for 3 epochs.\n",
        "\n",
        "The validation accuracy got to 65% \n",
        "\n",
        "If we were to scale up the number of images, we'd see the accuracy increase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSPoRj3PRi6l"
      },
      "source": [
        "## Making and evaluating predictions using a trained model\n",
        "\n",
        "\n",
        "Making predictions with a trained model is as calling `predict()` on it and passing it data in the same format the model was trained on.\n",
        "\n",
        "Before scaling up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvgSpSjySqIz"
      },
      "source": [
        "# Make predictions on the validation data (not used to train on)\n",
        "predictions = model.predict(val_data, verbose=1) # verbose shows us how long there is to go\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0v9awLqDtml"
      },
      "source": [
        "# Check the shape of predictions\n",
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhXvT9CeDzNE"
      },
      "source": [
        "Making predictions with our model returns an array with a different value for each label.\n",
        "\n",
        "In this case, making predictions on the validation data (200 images) returns an array (`predictions`) of arrays, each containing 120 different values (one for each unique dog breed).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUUDuXBlDy3i"
      },
      "source": [
        "# First prediction\n",
        "print(predictions[0])\n",
        "print(f\"Max value (probability of prediction): {np.max(predictions[0])}\") # the max probability value predicted by the model\n",
        "print(f\"Sum: {np.sum(predictions[0])}\") # because we used softmax activation in our model, this will be close to 1\n",
        "print(f\"Max index: {np.argmax(predictions[0])}\") # the index of where the max value in predictions[0] occurs\n",
        "print(f\"Predicted label: {unique_breeds[np.argmax(predictions[0])]}\") # the predicted label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3qFLiIrGRG8"
      },
      "source": [
        "### Compare a prediction to its true label and original image.\n",
        "\n",
        "Build a little function to convert prediction probabilities into predicted labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEUEsrlvG6Z2"
      },
      "source": [
        "# Turn prediction probabilities into their respective label (easier to understand)\n",
        "def get_pred_label(prediction_probabilities):\n",
        "  \"\"\"\n",
        "  Turns an array of prediction probabilities into a label.\n",
        "  \"\"\"\n",
        "  return unique_breeds[np.argmax(prediction_probabilities)]\n",
        "\n",
        "# Get a predicted label based on an array of prediction probabilities\n",
        "pred_label = get_pred_label(predictions[0])\n",
        "pred_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfjx3FPPHdQ7"
      },
      "source": [
        "We've got a list of all different predictions our model has made, we'll do the same for the validation images and validation labels.\n",
        "\n",
        "\n",
        "Since our validation data (`val_data`) is in batch form, to get a list of validation images and labels, we'll have to unbatch it (using [`unbatch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#unbatch)) and then turn it into an iterator using [`as_numpy_iterator()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#as_numpy_iterator).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEwoi7sjHdr_"
      },
      "source": [
        "# Create a function to unbatch a batched dataset\n",
        "def unbatchify(data):\n",
        "  \"\"\"\n",
        "  Takes a batched dataset of (image, label) Tensors and returns separate arrays\n",
        "  of images and labels.\n",
        "  \"\"\"\n",
        "  images = []\n",
        "  labels = []\n",
        "  # Loop through unbatched data\n",
        "  for image, label in data.unbatch().as_numpy_iterator():\n",
        "    images.append(image)\n",
        "    labels.append(unique_breeds[np.argmax(label)])\n",
        "  return images, labels\n",
        "\n",
        "# Unbatchify the validation data\n",
        "val_images, val_labels = unbatchify(val_data)\n",
        "val_images[0], val_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TWt_CvXLL-I"
      },
      "source": [
        "\n",
        "Now we make some functions to make these all a bit more visualize.\n",
        "\n",
        "The first function we'll create will:\n",
        "* Take an array of prediction probabilities, an array of truth labels, an array of images and an integer.\n",
        "* Convert the prediction probabilities to a predicted label.\n",
        "* Plot the predicted label, its predicted probability, the truth label and target image on a single plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YdcsHKlLMcW"
      },
      "source": [
        "def plot_pred(prediction_probabilities, labels, images, n=1):\n",
        "  \"\"\"\n",
        "  View the prediction, ground truth label and image for sample n.\n",
        "  \"\"\"\n",
        "  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n",
        "  \n",
        "  # Get the pred label\n",
        "  pred_label = get_pred_label(pred_prob)\n",
        "  \n",
        "  # Plot image & remove ticks\n",
        "  plt.imshow(image)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  # Change the color of the title depending on if the prediction is right or wrong\n",
        "  if pred_label == true_label:\n",
        "    color = \"green\"\n",
        "  else:\n",
        "    color = \"red\"\n",
        "\n",
        "  plt.title(\"{} {:2.0f}% ({})\".format(pred_label,\n",
        "                                      np.max(pred_prob)*100,\n",
        "                                      true_label),\n",
        "                                      color=color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMHqjvroLuMD"
      },
      "source": [
        "# View an example prediction, original image and truth label\n",
        "plot_pred(prediction_probabilities=predictions,\n",
        "          labels=val_labels,\n",
        "          images=val_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jEn2wQHdlJJ"
      },
      "source": [
        "\n",
        "\n",
        "Build a function that will:\n",
        "* Take an input of a prediction probabilities array, a ground truth labels array and an integer.\n",
        "* Find the predicted label using `get_pred_label()`.\n",
        "* Find the top 10:\n",
        "  * Prediction probabilities indexes\n",
        "  * Prediction probabilities values\n",
        "  * Prediction labels\n",
        "* Plot the top 10 prediction probability values and labels, coloring the true label green."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsWZOTMZNfha"
      },
      "source": [
        "def plot_pred_conf(prediction_probabilities, labels, n=1):\n",
        "  \"\"\"\n",
        "  Plots the top 10 highest prediction confidences along with\n",
        "  the truth label for sample n.\n",
        "  \"\"\"\n",
        "  pred_prob, true_label = prediction_probabilities[n], labels[n]\n",
        "\n",
        "  # Get the predicted label\n",
        "  pred_label = get_pred_label(pred_prob)\n",
        "\n",
        "  # Find the top 10 prediction confidence indexes\n",
        "  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n",
        "  # Find the top 10 prediction confidence values\n",
        "  top_10_pred_values = pred_prob[top_10_pred_indexes]\n",
        "  # Find the top 10 prediction labels\n",
        "  top_10_pred_labels = unique_breeds[top_10_pred_indexes]\n",
        "\n",
        "  # Setup plot\n",
        "  top_plot = plt.bar(np.arange(len(top_10_pred_labels)), \n",
        "                     top_10_pred_values, \n",
        "                     color=\"grey\")\n",
        "  plt.xticks(np.arange(len(top_10_pred_labels)),\n",
        "             labels=top_10_pred_labels,\n",
        "             rotation=\"vertical\")\n",
        "\n",
        "  # Change color of true label\n",
        "  if np.isin(true_label, top_10_pred_labels):\n",
        "    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n",
        "  else:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MgaCmh3Nkv0"
      },
      "source": [
        "plot_pred_conf(prediction_probabilities=predictions,\n",
        "               labels=val_labels,\n",
        "               n=9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Z-x-ZoOIzk"
      },
      "source": [
        "# check a few predictions and their different values\n",
        "i_multiplier = 0\n",
        "num_rows = 3\n",
        "num_cols = 2\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(5*2*num_cols, 5*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_pred(prediction_probabilities=predictions,\n",
        "            labels=val_labels,\n",
        "            images=val_images,\n",
        "            n=i+i_multiplier)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_pred_conf(prediction_probabilities=predictions,\n",
        "                labels=val_labels,\n",
        "                n=i+i_multiplier)\n",
        "plt.tight_layout(h_pad=1.0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d6kMp-iR4-y"
      },
      "source": [
        "## Saving and reloading a model\n",
        "\n",
        "The format of an [entire saved Keras model is h5](https://www.tensorflow.org/tutorials/keras/save_and_load). So we'll make a function which can take a model as input and utilise the [`save()`](https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format) method to save it as a h5 file to a specified directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-am2i8nfSok5"
      },
      "source": [
        "def save_model(model, suffix=None):\n",
        "  \"\"\"\n",
        "  Saves a given model in a models directory and appends a suffix (str)\n",
        "  for clarity and reuse.\n",
        "  \"\"\"\n",
        "  # Create model directory with current time\n",
        "  modeldir = os.path.join(\"drive/My Drive/Data/models\",\n",
        "                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n",
        "  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n",
        "  print(f\"Saving model to: {model_path}...\")\n",
        "  model.save(model_path)\n",
        "  return model_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1rmTJyejaYW"
      },
      "source": [
        "If we've got a saved model, we'd like to load it, let's create a function which can take a model path and use the [`tf.keras.models.load_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model) function to load it into the notebook.\n",
        "\n",
        "Because we're using a component from TensorFlow Hub (`hub.KerasLayer`) we'll have to pass this as a parameter to the `custom_objects` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTsodywBg-yH"
      },
      "source": [
        "def load_model(model_path):\n",
        "  \"\"\"\n",
        "  Loads a saved model from a specified path.\n",
        "  \"\"\"\n",
        "  print(f\"Loading saved model from: {model_path}\")\n",
        "  model = tf.keras.models.load_model(model_path,\n",
        "                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krU5fcPfH5Fx"
      },
      "source": [
        "# Save our model trained on 1000 images\n",
        "save_model(model, suffix=\"1000-images-Adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LT1pbHkIFK4"
      },
      "source": [
        "# Load our model trained on 1000 images\n",
        "model_1000_images = load_model('drive/My Drive/Data/models/20200131-02551580439347-1000-images-Adam.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBeDGM-IIrZY"
      },
      "source": [
        "Compare the two models (the original one and loaded one). We can do so easily using the `evaluate()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CKF9b7rIa-R"
      },
      "source": [
        "# Evaluate the pre-saved model\n",
        "model.evaluate(val_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAtcH95WIdem"
      },
      "source": [
        "# Evaluate the loaded model\n",
        "model_1000_images.evaluate(val_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fizd8NMSCDJ"
      },
      "source": [
        "## Training a model (on the full data)\n",
        "\n",
        "Now we know our model works on a subset of the data, we can start to move forward with training one on the full data.\n",
        "\n",
        "Above, we saved all of the training filepaths to `X` and all of the training labels to `y`. Let's check them out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KqIQCKtSpTS"
      },
      "source": [
        "# Remind ourselves of the size of the full dataset\n",
        "len(X), len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLDkGVtYDA7z"
      },
      "source": [
        "\n",
        "\n",
        "Before we can train a model on these, we'll have to turn them into a data batch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13KX_aZMI5Cu"
      },
      "source": [
        "# Turn full training data in a data batch\n",
        "full_data = create_data_batches(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km8ZJsXCJD8F"
      },
      "source": [
        "# Instantiate a new model for training on the full dataset\n",
        "full_model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E44JuJ7kD4t5"
      },
      "source": [
        "Since we've made a new model instance, `full_model`, we'll need some callbacks too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HY1RN2iKvDe"
      },
      "source": [
        "# Create full model callbacks\n",
        "\n",
        "# TensorBoard callback\n",
        "full_model_tensorboard = create_tensorboard_callback()\n",
        "\n",
        "# Early stopping callback\n",
        "# Note: No validation set when training on all the data, therefore can't monitor validation accruacy\n",
        "full_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n",
        "                                                             patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSqTuJ51LIes"
      },
      "source": [
        "To monitor the model whilst it trains, load TensorBoard "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXgEOvmeLrgJ"
      },
      "source": [
        "%tensorboard --logdir drive/My\\ Drive/Data/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihQ9LOHKNRWA"
      },
      "source": [
        "**Note:**  `full_model_early_stopping` callback will stop the training before it starts going for too long."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F0IjHkYJINx"
      },
      "source": [
        "# Fit the full model to the full training data\n",
        "full_model.fit(x=full_data,\n",
        "               epochs=NUM_EPOCHS,\n",
        "               callbacks=[full_model_tensorboard, \n",
        "                          full_model_early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK0CH96CMx17"
      },
      "source": [
        "### Saving and reloading the full model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TSB2BlbJI6o"
      },
      "source": [
        "# Save model to file\n",
        "save_model(full_model, suffix=\"all-images-Adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU50x9_ud_8h"
      },
      "source": [
        "# Load in the full model\n",
        "loaded_full_model = load_model('drive/My Drive/Data/models/20200131-03111580440309-all-images-Adam.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbZIu7gsSOnl"
      },
      "source": [
        "### Making predictions on the test dataset\n",
        "\n",
        "\n",
        "To make predictions on the test data:\n",
        "* Get the test image filenames.\n",
        "* Convert the filenames into test data batches using `create_data_batches()` and setting the `test_data` parameter to `True` (since there are no labels with the test images).\n",
        "* Make a predictions array by passing the test data batches to the `predict()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSsfWC7seJTu"
      },
      "source": [
        "# Load test image filenames (since we're using os.listdir(), these already have .jpg)\n",
        "test_path = \"drive/My Drive/Data/test/\"\n",
        "test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n",
        "\n",
        "test_filenames[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAk4DZcH9VNK"
      },
      "source": [
        "# How many test images are there?\n",
        "len(test_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWzszs_jeSax"
      },
      "source": [
        "# Create test data batch\n",
        "test_data = create_data_batches(test_filenames, test_data=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYdzux9IeUtf"
      },
      "source": [
        "# Make predictions on test data batch using the loaded full model\n",
        "# May take time\n",
        "test_predictions = loaded_full_model.predict(test_data,\n",
        "                                             verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CIvLI6xeZEl"
      },
      "source": [
        "# Check out the test predictions\n",
        "test_predictions[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NPOzuM6SZHM"
      },
      "source": [
        "### Preparing test dataset predictions for Kaggle\n",
        "\n",
        "Looking at the [Kaggle sample submission](https://www.kaggle.com/c/dog-breed-identification/overview/evaluation),  they want the models output probabilities each for label along with the image ID's.\n",
        "\n",
        "To get the data in this format, we'll:\n",
        "*   Create a pandas DataFrame with an ID column as well as a column for each dog breed.\n",
        "*   Add data to the ID column by extracting the test image ID's from their filepaths.\n",
        "* Add data (the prediction probabilities) to each of the dog breed columns using the `unique_breeds` list and the `test_predictions` list.\n",
        "* Export the DataFrame as a CSV to submit it to Kaggle.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAMYVd7dQ1dH"
      },
      "source": [
        "# Create pandas DataFrame with empty columns\n",
        "preds_df = pd.DataFrame(columns=[\"id\"] + list(unique_breeds))\n",
        "preds_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HD5dnPFe23V"
      },
      "source": [
        "# Append test image ID's to predictions DataFrame\n",
        "test_path = \"drive/My Drive/Data/test/\"\n",
        "preds_df[\"id\"] = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\n",
        "preds_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZwOW2CtCkRm"
      },
      "source": [
        "# Add the prediction probabilities to each dog breed column\n",
        "preds_df[list(unique_breeds)] = test_predictions\n",
        "preds_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAZR5Y7uEDU5"
      },
      "source": [
        "preds_df.to_csv(\"drive/My Drive/Data/submission_mobilienetV2_adam.csv\",\n",
        "                 index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}